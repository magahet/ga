{
  "status": "active", 
  "unique_views": 121, 
  "request_instructor_me": false, 
  "change_log": [
    {
      "type": "create", 
      "anon": "no", 
      "when": "2017-10-16T19:53:23Z", 
      "data": "j8ulks2zc8h53n", 
      "uid": "i4iys7m3lpq2ij"
    }, 
    {
      "uid": "i4hdvab632i522", 
      "type": "s_answer", 
      "when": "2017-10-17T08:05:26Z", 
      "to": "j8ulks2wihc53m", 
      "anon": "no", 
      "data": "j8vbq7c8al22jd"
    }, 
    {
      "to": "j8ulks2wihc53m", 
      "anon": "no", 
      "when": "2017-10-17T13:38:56Z", 
      "type": "followup", 
      "uid": "i4iys7m3lpq2ij"
    }
  ], 
  "upvote_ids": [], 
  "id": "j8ulks2wihc53m", 
  "bookmarked": 5, 
  "no_answer": 0, 
  "i_edits": [], 
  "is_bookmarked": false, 
  "children": [
    {
      "folders": [], 
      "is_tag_endorse": false, 
      "created": "2017-10-17T08:05:26Z", 
      "type": "s_answer", 
      "tag_endorse_arr": [], 
      "id": "j8vbq7c5g3o2jc", 
      "bucket_name": "Today", 
      "config": {}, 
      "tag_endorse": [], 
      "bucket_order": 2, 
      "data": {
        "embed_links": []
      }, 
      "children": [], 
      "history": [
        {
          "content": "I&#39;d say the data structure needn&#39;t be particularly smart, it&#39;s more the way you look up a value / the size of the array; for instance, assuming the vertices&#39; indices are a lookup into the array \u2013 say WLOG the vertices are numbered $$1,..n$$ \u2013 then you simply look up a boolean $$A[i]$$ in an array of length $$n$$ rather than iterating every element in an array of length $$|S|$$. You could equally simply store a bit flag with the adjacency list itself, then we interpret the lookup time to retrieve an individual node&#39;s adjacency list entry as $$O(1)$$ similarly", 
          "anon": "no", 
          "created": "2017-10-17T08:05:26Z", 
          "uid": "i4hdvab632i522", 
          "subject": ""
        }
      ]
    }, 
    {
      "folders": [], 
      "updated": "2017-10-17T13:38:56Z", 
      "no_upvotes": 0, 
      "uid": "i4iys7m3lpq2ij", 
      "created": "2017-10-17T13:38:56Z", 
      "type": "followup", 
      "no_answer": 0, 
      "id": "j8vnn37mn249z", 
      "anon": "no", 
      "bucket_name": "Today", 
      "config": {}, 
      "bucket_order": 2, 
      "data": {
        "embed_links": null
      }, 
      "children": [], 
      "subject": "<p>Hey Mark,\u00a0thanks, I see that. In my mind, it&#39;s still a step beyond the obvious array lookup, but as long as that&#39;s what&#39;s going on, the runtime makes sense.</p>"
    }
  ], 
  "nr": 736, 
  "bucket_order": 2, 
  "type": "question", 
  "folders": [
    "hw_solutions5"
  ], 
  "no_answer_followup": 0, 
  "num_favorites": 4, 
  "bucket_name": "Today", 
  "q_edits": [], 
  "data": {
    "embed_links": []
  }, 
  "request_instructor": 0, 
  "tags": [
    "hw_solutions5", 
    "student"
  ], 
  "created": "2017-10-16T19:53:23Z", 
  "is_tag_good": false, 
  "config": {}, 
  "s_edits": [], 
  "my_favorite": false, 
  "default_anonymity": "no", 
  "t": 1509145145704, 
  "tag_good": [
    {
      "name": "Dennis Sidharta", 
      "admin": false, 
      "photo": "1463366773_35.png", 
      "us": false, 
      "role": "student", 
      "facebook_id": null, 
      "id": "idg5nm2lC96"
    }
  ], 
  "tag_good_arr": [
    "idg5nm2lC96"
  ], 
  "history": [
    {
      "content": "<p>I realize this is inconsequential to the overall runtime of the bottleneck algorithm, but I want to be sure I&#39;m not missing something.</p>\n<p></p>\n<p>It seems to me that, as written, step 4: &#34;For each $$(u, v) \\in E(G)$$, return $$(u, v)$$ if $$u \\in S$$ and $$v \\in T$$.&#34; should take $$O(nm)$$ time, not $$O(n&#43;m)$$, as stated.\u00a0</p>\n<p></p>\n<p>We loop through $$m$$ edges and for each edge, we have to do an $$O(n)$$ search through arrays $$S$$ and $$T$$. Granted, for edges with the same source, we don&#39;t have to re-search $$S$$, but I don&#39;t think this changes the Big-O. So it seems to me that no matter what (well, unless we use a different data structure), we do $$O(n)$$ work per edge. This seems fundamentally different than BFS/DFS or reversing a graph, wherein once we visit an edge, we don&#39;t visit it again, which means we do a sum total of $$O(m)$$ work for all $$n$$ vertices rather than $$O(m)$$ work for each of the $$n$$ vertices.\u00a0</p>\n<p></p>\n<p>Of course, if we used a smarter data structure in place of an array for $$S$$ and $$T$$, we could reduce our search to $$O(1)$$, which would achieve an $$O(n&#43;m)$$ runtime. But as this wasn&#39;t mentioned, I assume it wasn&#39;t used for the runtime computation.</p>", 
      "anon": "no", 
      "created": "2017-10-16T19:53:23Z", 
      "uid": "i4iys7m3lpq2ij", 
      "subject": "Minor runtime detail Problem 1, algorithm step 4"
    }
  ]
}